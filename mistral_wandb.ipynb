{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urSaPCZoqEmM"
      },
      "source": [
        "# Mistral and Weights & Biases\n",
        "\n",
        "- Weights & Biases: https://wandb.ai/\n",
        "- Mistral finetuning docs: https://docs.mistral.ai/capabilities/finetuning/\n",
        "- Tracing with W&B Weave: https://wandb.me/weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install mistralai pandas weave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Mistral and Weave\n",
        "\n",
        "You will probably integrate MistralAI API calls in your codebase by creating a function like the one below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, asyncio\n",
        "import weave\n",
        "from mistralai.async_client import MistralAsyncClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "client = MistralAsyncClient(api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
        "\n",
        "@weave.op()  # <---- add this and you are good to go\n",
        "async def call_mistral(model:str, messages:list, **kwargs) -> str:\n",
        "    \"Call the Mistral API\"\n",
        "    chat_response = await client.chat(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        **kwargs,\n",
        "    )\n",
        "    return chat_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The only thing you need to do is add the @weave.op() decorator to the function you want to trace.\n",
        "\n",
        "Let's define a more interesting function that recommends cheese based on the region and model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "@weave.op()\n",
        "async def cheese_recommender(region:str, model:str) -> str:\n",
        "    \"Recommend the best cheese in a given region\"\n",
        "     \n",
        "    messages = [ChatMessage(\n",
        "        role=\"user\", \n",
        "        content=f\"What is the best cheese in {region}?\")]\n",
        "\n",
        "    cheeses = await call_mistral(model=model, messages=messages)\n",
        "    return {\"region\": region, \"cheeses\": cheeses}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's run this function and see how weave traces it. We call weave.init() to tell weave the project where to store the traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as Weights & Biases user: capecape.\n",
            "View Weave data at https://wandb.ai/capecape/mistral_webinar/weave\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/e30abb50-3879-43d7-8ae1-afb22d7f2bb1\n",
            "{'region': 'France', 'cheeses': 'France is renowned for its diverse and high-quality cheeses, and the \"best\" cheese can often be subjective as it depends on personal taste. However, one of the most famous French cheeses is Roquefort, a blue cheese made from sheep\\'s milk. It\\'s known for its strong flavor and distinctive veining.\\n\\nAnother popular French cheese is Brie de Meaux, a soft, creamy cheese with a mild, slighty nutty flavor. Camembert, a relative of Brie, is also well-loved, especially outside of France.\\n\\nFor those who prefer harder cheeses, Comt√©, a nutty and slightly sweet cheese, is a good choice. And let\\'s not forget about Munster, a soft, pungent cheese with a distinctive texture and strong aroma.\\n\\nEach region in France has its own unique cheeses, so there\\'s a wide variety to explore. It\\'s all about finding the cheese that suits your taste buds!'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "weave.init(\"mistral_webinar\")\n",
        "out = await cheese_recommender(region=\"France\", model=\"open-mistral-7b\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can view the traces by clicking the link above üëÜ\n",
        "![](cheese_recomender.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27PpM60GqRvR"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "Some data from wandbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json('qa.jsonl', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the difference between team and organi...</td>\n",
              "      <td>A team is a collaborative workspace for a grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the difference between team and entity...</td>\n",
              "      <td>A team is a collaborative workspace for a grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is a team and where can I find more infor...</td>\n",
              "      <td>Use W&amp;B Teams as a central workspace for your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When should I log to my personal entity agains...</td>\n",
              "      <td>You should log to your personal entity when yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who can create a team? Who can add or delete p...</td>\n",
              "      <td>**Admin**: Team admins can add and remove othe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the difference between team and organi...   \n",
              "1  What is the difference between team and entity...   \n",
              "2  What is a team and where can I find more infor...   \n",
              "3  When should I log to my personal entity agains...   \n",
              "4  Who can create a team? Who can add or delete p...   \n",
              "\n",
              "                                              answer  \n",
              "0  A team is a collaborative workspace for a grou...  \n",
              "1  A team is a collaborative workspace for a grou...  \n",
              "2  Use W&B Teams as a central workspace for your ...  \n",
              "3  You should log to your personal entity when yo...  \n",
              "4  **Admin**: Team admins can add and remove othe...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's split into train/valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(114, 13)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train=df.sample(frac=0.9,random_state=200)\n",
        "df_eval=df.drop(df_train.index)\n",
        "len(df_train), len(df_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A neat trick to get better answers is instead of passing a very long initial message, passing a small conversation with some prefilled agent responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_messages(question: str, cls=ChatMessage):\n",
        "    messages = [\n",
        "        cls(\n",
        "            role=\"user\", \n",
        "            content=(\n",
        "                \"You are an expert about Weights & Biases the ML platform. \"\n",
        "                 \"You will answer questions about the product, Answer the question directly, without repeating the instructions.\"\n",
        "                 )\n",
        "        ),\n",
        "        cls(\n",
        "            role=\"assistant\", \n",
        "            content=(\n",
        "                \"Sure, I'd be happy to help with your question about Weights & Biases. \"\n",
        "                 \"If you have a specific question about using Weights & Biases, such as how to track experiments, \"\n",
        "                 \"visualize data, or manage artifacts, please feel free to ask!\")\n",
        "        ),\n",
        "        cls(\n",
        "            role=\"user\", \n",
        "            content=f\"Here is the question: {question}\"\n",
        "        )\n",
        "    ]\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/264ede4c-e236-4805-a3ef-54d62c4c763c\n",
            "What is the difference between team and organization?\n",
            "In Weights & Biases (W&B), the difference between a team and an organization is primarily in terms of access control and collaboration.\n",
            "\n",
            "A team is a group of users who are working together on a specific project or set of experiments. Teams can be created and managed by any W&B user, and team members can be added or removed as needed. Teams can also have different access levels for different members, such as read-only or admin access.\n",
            "\n",
            "An organization, on the other hand, is a higher-level entity that can contain multiple teams. Organizations are typically used to manage larger groups of users, such as a company or research lab, and provide centralized management and administration of W&B resources. Organizations can also have different access levels for different members, and can have custom branding and billing options.\n",
            "\n",
            "In summary, teams are used for smaller-scale collaboration and experiment management, while organizations are used for larger-scale management of W&B resources and users.\n"
          ]
        }
      ],
      "source": [
        "@weave.op()\n",
        "async def wandb_expert(question:str, model:str) -> str:\n",
        "    \"Answer questions about wandb\"\n",
        "     \n",
        "    messages = create_messages(question=question)\n",
        "\n",
        "    answer = await call_mistral(model=model, messages=messages)\n",
        "    return {\"question\": question, \"answer\": answer}\n",
        "\n",
        "res = await wandb_expert(question=df.loc[0].question, model=\"mistral-medium-latest\")\n",
        "print(df.loc[0].question)\n",
        "print(res[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GT dataset\n",
        "Let's create a dataset with mistral-medium-latest as our baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MistralModel(weave.Model):\n",
        "    model: str\n",
        "    temperature: float = 0.7\n",
        "    \n",
        "    @weave.op\n",
        "    def create_messages(self, question:str):\n",
        "        return create_messages(question)\n",
        "\n",
        "    @weave.op\n",
        "    async def predict(self, question:str):\n",
        "        messages = self.create_messages(question)\n",
        "        return await call_mistral(model=self.model, messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = weave.Dataset(name=\"ds_train\", rows=df_train)\n",
        "ds_eval = weave.Dataset(name=\"ds_eval\", rows=df_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "let's publish them to Weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Published to https://wandb.ai/capecape/mistral_webinar/weave/objects/ds_train/versions/ZFlKJFzLHbwN6w5bxi1pVRkkBiYZNF4zEqHrKUSDkYI\n",
            "üì¶ Published to https://wandb.ai/capecape/mistral_webinar/weave/objects/ds_eval/versions/6nj1RQhTJNCezToyNmZNScj7MCHYKCjBoLMvuNHDeBE\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ObjectRef(entity='capecape', project='mistral_webinar', name='ds_eval', digest='6nj1RQhTJNCezToyNmZNScj7MCHYKCjBoLMvuNHDeBE', extra=[])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weave.publish(ds_train)\n",
        "weave.publish(ds_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets create a dataset with the medium model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "mistral_medium = MistralModel(model=\"mistral-medium-latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def async_foreach(sequence, func, max_concurrent_tasks):\n",
        "    \"Handy parallelism async for looper\"\n",
        "    semaphore = asyncio.Semaphore(max_concurrent_tasks)\n",
        "    async def process_item(item):\n",
        "        async with semaphore:\n",
        "            result = await func(item)\n",
        "            return item, result\n",
        "\n",
        "    tasks = [asyncio.create_task(process_item(item)) for item in sequence]\n",
        "\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        item, result = await task\n",
        "        yield item, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/a1d56ca5-4848-4b81-84e8-1ddaf5d8b3e0\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/4762498a-f2e8-4101-87bf-3033e7feb2b7\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/169e279e-cb74-4a5e-bf9e-465b605e7fce\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/b6bc1c9b-d71e-41c2-8562-441b2e665c6e\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/08a7a5f8-c85e-4a97-aaca-8d805b9ec49f\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/3ee07b19-9553-4f32-8a67-53a8fdee90b0\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/00aef0ec-76ef-47d1-ac18-e3b642437f9b\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/8f09d532-e6ef-4cb2-a1d7-d8b0f6f4d9ff\n"
          ]
        }
      ],
      "source": [
        "async def map(ds, func, max_concurrent_tasks = 7, col_name=\"mistral_medium\"):\n",
        "    new_dataset = []\n",
        "    async for example, map_results in async_foreach(ds.rows, func, max_concurrent_tasks):\n",
        "        example.update({col_name: map_results})\n",
        "        new_dataset.append(example)\n",
        "    return new_dataset\n",
        "\n",
        "ds_eval_medium_rows = await map(ds_eval, mistral_medium.predict, col_name=\"mistral-medium\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Published to https://wandb.ai/capecape/mistral_webinar/weave/objects/ds_eval_medium/versions/JX9ZhLO7D0TU9R0d8LSBiluUnVSByahEqtoy7skrqnQ\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ObjectRef(entity='capecape', project='mistral_webinar', name='ds_eval_medium', digest='JX9ZhLO7D0TU9R0d8LSBiluUnVSByahEqtoy7skrqnQ', extra=[])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_eval_medium = weave.Dataset(name=\"ds_eval_medium\", description=\"Mistral medium predictions\", rows=ds_eval_medium_rows)\n",
        "weave.publish(ds_eval_medium)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can pull your data back easily using the API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_eval_medium = weave.ref('ds_eval_medium:v0').get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TraceDict({'question': 'How often are system metrics collected?', 'answer': 'By default, metrics are collected every 2 seconds and averaged over a 15-second period. If you need higher resolution metrics, email us a [contact@wandb.com](mailto:contact@wandb.com).', 'mistral-medium': 'In Weights & Biases, system metrics are collected by default every 2 seconds and then averaged over a 15-second period. However, if you need higher resolution metrics, you can contact Weights & Biases support at [contact@wandb.com](mailto:contact@wandb.com) to request customization of the metric collection interval.'}),\n",
              " TraceDict({'question': 'What is the difference between `.log()` and `.summary`?', 'answer': 'The summary is the value that shows in the table while the log will save all the values for plotting later.\\n\\nFor example, you might want to call `wandb.log` every time the accuracy changes. Usually, you can just use .log. `wandb.log()` will also update the summary value by default unless you have set the summary manually for that metric\\n\\nThe scatterplot and parallel coordinate plots will also use the summary value while the line plot plots all of the values set by .log\\n\\nThe reason we have both is that some people like to set the summary manually because they want the summary to reflect for example the optimal accuracy instead of the last accuracy logged.\\n', 'mistral-medium': \"The difference between Weights & Biases' `.log()` and `.summary` functions is that `.summary()` sets the summary value for a given metric in the Weights & Biases table, while `.log()` saves the value for plotting later. By default, `.log()` also updates the summary value, but you can set the summary manually using `.summary()`. The scatterplot and parallel coordinate plots use the summary value, while the line plot uses all values logged by `.log()`. The reason for having both functions is to allow users to manually set the summary value to reflect the optimal accuracy or other desired metric, rather than the last logged value.\"}),\n",
              " TraceDict({'question': 'What are some use-cases where you can use wandb sync', 'answer': '\\n\\n- If you don‚Äôt have internet.\\n- If you need to fully disable things.\\n- To sync your run later due to any reason. For instance: if you want to avoid using resources on a training machine.\\n', 'mistral-medium': \"The use-cases you provided for using wandb sync are correct. Here's a bit more context:\\n\\n* If you don't have internet: wandb sync allows you to log your metrics locally and sync them with Weights & Biases when you have internet access later. This can be useful in situations where you're training models in remote locations or on machines without internet access.\\n* If you need to fully disable things: wandb sync allows you to disable logging altogether by using the `--disable` flag. This can be useful if you're working with sensitive data and don't want to log anything at all.\\n* To sync your run later: wandb sync allows you to log your metrics locally and then sync them with Weights & Biases at a later time. This can be useful if you want to avoid using resources on a training machine, or if you want to wait until you have a stable internet connection before syncing your metrics.\\n\\nOverall, wandb sync provides a flexible way to log and sync your metrics, giving you more control over when and how you share your data with Weights & Biases.\"}),\n",
              " TraceDict({'question': 'How do I avoid common distributed training issues?', 'answer': 'Use W&B Service to avoid common distributed training issues.\\n\\nThere are two common issues you might encounter when using W&B and distributed training:\\n\\n1. **Hanging at the beginning of training** - A `wandb` process can hang if the `wandb` multiprocessing interferes with the multiprocessing from distributed training.\\n2. **Hanging at the end of training** - A training job might hang if the `wandb` process does not know when it needs to exit. Call the `wandb.finish()` API at the end of your Python script to tell W&B that the Run finished. The wandb.finish() API will finish uploading data and will cause W&B to exit.\\n\\nWe recommend using the `wandb service` to improve the reliability of your distributed jobs. Both of the preceding training issues are commonly found in versions of the W&B SDK where wandb service is unavailable.\"\\n', 'mistral-medium': 'The answer provided in the TraceDict suggests that using the W&B Service can help avoid common distributed training issues when using Weights & Biases. Specifically, there are two common issues that users might encounter:\\n\\n1. **Hanging at the beginning of training:** This issue can occur if the multiprocessing used by Weights & Biases interferes with the multiprocessing used for distributed training.\\n2. **Hanging at the end of training:** This issue can occur if the Weights & Biases process does not know when to exit, causing the training job to hang.\\n\\nTo avoid these issues, the answer suggests using the `wandb service` to improve the reliability of distributed jobs. This service is available in newer versions of the Weights & Biases SDK and can help prevent these common issues.\\n\\nAdditionally, the answer suggests calling the `wandb.finish()` API at the end of your Python script to tell Weights & Biases that the run has finished, which will cause the Weights & Biases process to exit and finish uploading data.\\n\\nI hope this helps! Let me know if you have any further questions.'}),\n",
              " TraceDict({'question': \"I'm getting the following error : `InitStartError: Error communicating with wandb process` \", 'answer': 'This error indicates that the library is having difficulty launching the process which synchronizes data to the server.\\n\\nThe following workarounds can help resolve the issue in certain environments:\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"fork\"))\\n```\\n\\nFor versions prior to `0.13.0` we suggest using:\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"thread\"))\\n```\\n', 'mistral-medium': 'The error you\\'re seeing with Weights & Biases (W&B) indicates that there is an issue with starting the process that synchronizes data to the W&B server. This can sometimes occur in certain environments or configurations.\\n\\nOne possible solution is to specify the \"fork\" start method when initializing W&B, which launches a new process to handle synchronization. You can do this by calling `wandb.init(settings=wandb.Settings(start_method=\"fork\"))`.\\n\\nIf you are using an older version of W&B (prior to 0.13.0), you can try using the \"thread\" start method instead, which launches a new thread to handle synchronization. You can do this by calling `wandb.init(settings=wandb.Settings(start_method=\"thread\"))`.\\n\\nI hope this helps! If you continue to experience issues, please let me know and I\\'ll do my best to assist you further.'}),\n",
              " TraceDict({'question': 'How can I organize my logged charts and media in the W&B UI?', 'answer': 'We treat `/` as a separator for organizing logged panels in the W&B UI. By default, the component of the logged item\\'s name before a `/` is used to define a group of panel called a \"Panel Section\".\\n\\n```\\nwandb.log({\"val/loss\": 1.1, \"val/acc\": 0.3})\\nwandb.log({\"train/loss\": 0.1, \"train/acc\": 0.94})\\n```\\n\\nIn the Workspace settings, you can change whether panels are grouped by just the first component or by all components separated by `/`.\\n', 'mistral-medium': 'To organize your logged charts and media in the Weights & Biases (W&B) UI, you can use `/` as a separator in the logged item\\'s name. By default, the component before the `/` is used to define a group of panels called a \"Panel Section.\"\\n\\nFor example, if you log the following values:\\n```python\\nwandb.log({\"val/loss\": 1.1, \"val/acc\": 0.3})\\nwandb.log({\"train/loss\": 0.1, \"train/acc\": 0.94})\\n```\\nThe \"val\" and \"train\" components before the `/` will create two separate Panel Sections in the W&B UI, with the \"loss\" and \"acc\" components displayed as individual panels within each section.\\n\\nYou can also customize the grouping of panels in the Workspace settings. By default, panels are grouped by just the first component before the `/`. However, you can change this setting to group panels by all components separated by `/`. This can be useful if you have a lot of related panels with the same prefix.\\n\\nI hope this helps! Let me know if you have any further questions.'}),\n",
              " TraceDict({'question': 'What happens if I pass a class attribute into wandb.log()?', 'answer': 'It is generally not recommended to pass class attributes into `wandb.log()` as the attribute may change before the network call is made. If you are storing metrics as the attribute of a class, it is recommended to deep copy the attribute to ensure the metric logged matches the value of the attribute at the time that `wandb.log()` was called.', 'mistral-medium': 'The provided question and answer seem to be related to Weights & Biases (W&B), but the information is more specific to the `wandb` library, which is often used in conjunction with W&B.\\n\\nIn any case, the answer is correct. Passing a class attribute into `wandb.log()` may result in unexpected behavior, as the attribute value may change before the network call is made. To ensure that the logged metric matches the attribute value at the time of the call, it is recommended to deep copy the attribute before passing it to `wandb.log()`.\\n\\nIn W&B, the equivalent function to `wandb.log()` is `wandb.log()`, which functions similarly. Therefore, the same recommendation applies to logging class attributes in W&B.'}),\n",
              " TraceDict({'question': 'How can I access the data logged to my runs directly and programmatically?', 'answer': 'The history object is used to track metrics logged by `wandb.log`. Using our import/export API, you can access the history object via `run.history()`.\\n\\n```python\\napi = wandb.Api()\\nrun = api.run(\"username/project/run_id\")\\nprint(run.history())\\n```\\n', 'mistral-medium': 'Great question! To access the data logged to your runs directly and programmatically, you can use the Weights & Biases (W&B) Python API. Specifically, you can use the `run.history()` method to retrieve the history object for a given run.\\n\\nHere\\'s an example of how you can use the W&B API to access the history object for a given run:\\n```python\\nimport wandb\\n\\n# Initialize a new Weights & Biases run\\nrun = wandb.init(project=\"my-project\")\\n\\n# Log some data to the run\\nwandb.log({\"loss\": 0.1, \"accuracy\": 0.9})\\n\\n# Wait for the run to finish (or for enough data to be logged)\\n# ...\\n\\n# Retrieve the run object using the W&B API\\napi = wandb.Api()\\nrun = api.run(\"username/my-project/run_id\")\\n\\n# Access the history object for the run\\nhistory = run.history()\\n\\n# Print the history object\\nprint(history)\\n```\\nIn this example, we first initialize a new W&B run using the `wandb.init()` method. We then log some data to the run using the `wandb.log()` method.\\n\\nOnce we have enough data logged to the run, we can retrieve the run object using the `wandb.Api().run()` method, passing in the username, project name, and run ID. We can then access the history object for the run using the `run.history()` method.\\n\\nThe history object contains a dictionary of all the metrics and data that have been logged to the run. You can access the data in the history object programmatically, just like you would any other Python dictionary.\\n\\nI hope that helps! Let me know if you have any further questions.'}),\n",
              " TraceDict({'question': 'What formula do you use for your smoothing algorithm?', 'answer': 'We use the same exponential moving average formula as TensorBoard. \\n\\nAssuming all the real scalar values are in a list called scalars the smoothing is applied as follows:\\n\\n```\\ndef smooth(scalars: List[float], weight: float) -> List[float]:  # Weight between 0 and 1\\n    last = scalars[0]  # First value in the plot (first timestep)\\n    smoothed = list()\\n    for point in scalars:\\n        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\\n        smoothed.append(smoothed_val)                        # Save it\\n        last = smoothed_val                                  # Anchor the last smoothed value\\n        \\n    return smoothed\\n```\\n', 'mistral-medium': 'Weights & Biases uses the same exponential moving average (EMA) formula as TensorBoard for its smoothing algorithm. The formula is defined as follows:\\n\\n`smoothed\\\\_val = last \\\\* weight + (1 - weight) \\\\* point`\\n\\nWhere:\\n\\n* `last` is the last smoothed value\\n* `weight` is a value between 0 and 1 that determines the degree of smoothing\\n* `point` is the current scalar value\\n\\nThe algorithm calculates a smoothed value for each scalar in a list of scalars, and returns a new list containing all the smoothed values. The first value in the smoothed list is the same as the first value in the input list.\\n\\nHere is an example of how the smoothing algorithm works:\\n\\nSuppose we have a list of scalars `[1, 2, 3, 4, 5]` and we want to apply smoothing with a weight of 0.8.\\n\\n1. Initialize the `last` variable to the first value in the list, which is 1.\\n2. For each scalar value in the list, calculate the smoothed value using the formula above:\\n* For the first scalar value 1, the smoothed value is the same as the input value: `1 * 0.8 + (1 - 0.8) * 1 = 1`\\n* For the second scalar value 2, the smoothed value is: `1 * 0.8 + (1 - 0.8) * 2 = 1.6`\\n* For the third scalar value 3, the smoothed value is: `1.6 * 0.8 + (1 - 0.8) * 3 = 2.44`\\n* For the fourth scalar value 4, the smoothed value is: `2.44 * 0.8 + (1 - 0.8) * 4 = 3.328`\\n* For the fifth scalar value 5, the smoothed value is: `3.328 * 0.8 + (1 - 0.8) * 5 = 4.2624`\\n3. The final list of smoothed values is `[1, 1.6, 2.44, 3.328, 4.2624]`.\\n\\nAs you can see, the smoothed values are less jagged than the original scalar values, and better reflect the overall trend of the data.'}),\n",
              " TraceDict({'question': 'Can Launch automatically provision (and spin down) compute resources for me in the target environment?', 'answer': 'Yes. This depends on the environment, we are able to provision resources in SageMaker, and Vertex. In Kubernetes, autoscalers can be used to automatically spin up and spin down resources when required. The Solution Architects at W&B are happy to work with you to configure your underlying Kubernetes infrastructure to facilitate retries, autoscaling, and use of spot instance node pools. Reach out to support@wandb.com or your shared Slack channel.', 'mistral-medium': 'Yes, Weights & Biases (W&B) can automatically provision and spin down compute resources in certain environments. Specifically, W&B supports automatic resource provisioning in Amazon SageMaker and Google Vertex AI.\\n\\nIn Kubernetes, W&B can integrate with Kubernetes autoscalers to automatically scale resources up and down as required. The W&B Solution Architects can work with you to configure your underlying Kubernetes infrastructure to facilitate retries, autoscaling, and use of spot instance node pools.\\n\\nIf you have any further questions or need help configuring automatic resource provisioning, you can reach out to W&B support at [support@wandb.com](mailto:support@wandb.com) or your shared Slack channel.'}),\n",
              " TraceDict({'question': 'Are there best practices for using Launch effectively?', 'answer': \"Yes. Here are some best practices to consider when using Launch:\\n\\n  1. Create your queue before you start your agent, so that you can set your agent to point to it easily.  If you don‚Äôt do this, your agent will give errors and not work until you add a queue.\\n  2. Create a W&B service account to start up the agent, so that it's not tied to an individual user account.\\n  3. Use `wandb.config` to read and write your hyperparameters, so that they can be overwritten when re-running a job.\\n\", 'mistral-medium': \"The answer provided is correct. Here are some additional best practices for using Launch effectively:\\n\\n1. Use the `launch.run()` function to wrap your training script, which will automatically log all your metrics and artifacts to Weights & Biases.\\n2. Use the `--launch_project` flag to specify the project name when running your script, so that all your experiments are grouped together in one place.\\n3. Use the `--launch_job_type` flag to specify the job type, so that you can easily filter and search for specific types of experiments.\\n4. Use the `--launch_description` flag to add a description to your job, so that you can easily identify it in the W&B UI.\\n5. Use the `--launch_group` flag to group related jobs together, so that you can easily compare and analyze their results.\\n6. Use the `--launch_tags` flag to add tags to your job, so that you can easily filter and search for specific jobs.\\n7. Use the `--launch_log_artifact` flag to log large files, such as models or datasets, as artifacts, so that they are not included in the metric logs.\\n8. Use the `--launch_max_retries` flag to specify the maximum number of times a job should be retried in case of failure, so that you don't have to manually restart failed jobs.\\n9. Use the `--launch_ GPU` flag to specify the number of GPUs to use for your training script, so that you can easily scale up your training.\\n10. Use the `--launch_log_env` flag to log environment variables, so that you can easily reproduce your training environment.\\n\\nBy following these best practices, you can make the most of Launch and easily manage and compare your machine learning experiments.\"}),\n",
              " TraceDict({'question': 'How do I log an artifact to an existing run?', 'answer': 'Occasionally, you may want to mark an artifact as the output of a previously logged run. In that scenario, you can reinitialize the old run and log new artifacts to it as follows:\\n\\n```\\nwith wandb.init(id=\"existing_run_id\", resume=\"allow\") as run:\\n    artifact = wandb.Artifact(\"artifact_name\", \"artifact_type\")\\n    artifact.add_file(\"my_data/file.txt\")\\n    run.log_artifact(artifact)\\n```\\n', 'mistral-medium': 'To log an artifact to an existing run in Weights & Biases (W&B), you can reinitialize the old run using the `wandb.init()` function and set the `resume` parameter to `\"allow\"`. This will allow you to add new data to the existing run.\\n\\nHere\\'s an example code snippet that demonstrates how to log an artifact to an existing run:\\n```\\nimport wandb\\n\\n# Specify the run ID of the existing run\\nrun_id = \"existing_run_id\"\\n\\n# Reinitialize the existing run with the resume parameter set to \"allow\"\\nwith wandb.init(id=run_id, resume=\"allow\") as run:\\n\\n  # Create an artifact object with the desired name and type\\n  artifact = wandb.Artifact(\"artifact_name\", \"artifact_type\")\\n\\n  # Add a file to the artifact object\\n  artifact.add_file(\"my_data/file.txt\")\\n\\n  # Log the artifact to the existing run\\n  run.log_artifact(artifact)\\n```\\nIn this example, the `run_id` variable specifies the ID of the existing run that you want to add the artifact to. The `wandb.Artifact()` function creates a new artifact object with the desired name and type. The `add_file()` method is used to add a file to the artifact object, and the `log_artifact()` method is used to log the artifact to the existing run.\\n\\nNote that if the specified run ID does not already exist, the `wandb.init()` function will create a new run with the specified ID instead of resuming an existing run.'}),\n",
              " TraceDict({'question': 'Do I need to provide values for all hyperparameters as part of the W&B Sweep. Can I set defaults?', 'answer': 'The hyperparameter names and values specified as part of the sweep configuration are accessible in `wandb.config`, a dictionary-like object.\\n\\nFor runs that are not part of a sweep, the values of `wandb.config` are usually set by providing a dictionary to the `config` argument of `wandb.init`. During a sweep, however, any configuration information passed to `wandb.init` is instead treated as a default value, which might be over-ridden by the sweep.\\n\\nYou can also be more explicit about the intended behavior by using `config.setdefaults`. The following code snippets for both methods are shown below:\\n\\nusing wandb.init\\n\\n```\\n# set default values for hyperparameters\\nconfig_defaults = {\"lr\": 0.1, \"batch_size\": 256}\\n\\n# start a run, providing defaults\\n#   that can be over-ridden by the sweep\\nwith wandb.init(config=config_default) as run:\\n    # add your training code here\\n    ...\\n```\\n\\nusing config.setdefaults\\n\\n```\\n# set default values for hyperparameters\\nconfig_defaults = {\"lr\": 0.1, \"batch_size\": 256}\\n\\n# start a run\\nwith wandb.init() as run:\\n    # update any values not set by sweep\\n    run.config.setdefaults(config_defaults)\\n\\n    # add your training code here\\n```  \\n', 'mistral-medium': 'No, you do not need to provide values for all hyperparameters as part of a Weights & Biases (W&B) sweep. You can set default values for any hyperparameters that you do not specify in the sweep configuration.\\n\\nTo set default values, you can use the `config` argument of `wandb.init()` to pass in a dictionary of hyperparameter names and values. During a sweep, these values will be treated as defaults and may be overridden by the sweep configuration.\\n\\nAlternatively, you can use the `setdefaults()` method of the `wandb.config` object to update any hyperparameter values that have not been set by the sweep. This can be useful if you want to specify default values for some hyperparameters, but allow the sweep to override them for certain runs.\\n\\nHere\\'s an example of how to use `wandb.init()` to set default values:\\n```\\n# set default values for hyperparameters\\nconfig_defaults = {\"lr\": 0.1, \"batch_size\": 256}\\n\\n# start a run, providing defaults\\n#   that can be over-ridden by the sweep\\nwith wandb.init(config=config_defaults) as run:\\n    # add your training code here\\n    ...\\n```\\nAnd here\\'s an example of how to use `setdefaults()` to set default values:\\n```\\n# set default values for hyperparameters\\nconfig_defaults = {\"lr\": 0.1, \"batch_size\": 256}\\n\\n# start a run\\nwith wandb.init() as run:\\n    # update any values not set by sweep\\n    run.config.setdefaults(config_defaults)\\n\\n    # add your training code here\\n    ...\\n```\\nI hope that helps! Let me know if you have any other questions about using Weights & Biases.'})]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(ds_eval_medium.rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's add the results of Mistral 7B (non finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/6caf9e2e-4677-4bec-adfb-fd676143211c\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/2171b067-d319-45e1-8ad6-02d83c8c0cc0\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/6394d286-b455-4d38-8136-a42623f8b9f4\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/bea011b4-1564-4b01-ab3f-2570cbfbbb04\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/b288e3ba-4357-4e0c-85b2-dd2c46f66ae5\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/11c07aad-438c-42ae-943b-4dc2e21ea4a1\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/4833ab50-9794-4559-85f1-88100153953c\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/f36b04a6-3b9c-4799-9bec-35851b39e493\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/3375bb57-5c55-4130-a187-dda4b6d301f0\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/a1b43519-24da-496d-834a-6d3820daec5c\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/c8fe5ed4-699f-4136-bae8-2c8791ad9e96\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/25b346fd-a3e7-4d9d-8498-2c14e5b1fec3\n",
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/4c1f4d01-186a-41f9-a39a-4335d691b254\n",
            "üì¶ Published to https://wandb.ai/capecape/mistral_webinar/weave/objects/ds_eval_medium_7b/versions/xdrfHXg1hhfxDiUdJsvLiAM15aE9r0tD7YIPMTXEzrM\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ObjectRef(entity='capecape', project='mistral_webinar', name='ds_eval_medium_7b', digest='xdrfHXg1hhfxDiUdJsvLiAM15aE9r0tD7YIPMTXEzrM', extra=[])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral_7b = MistralModel(model=\"open-mistral-7b\")\n",
        "ds_eval_7b_rows = await map(ds_eval_medium, mistral_7b.predict, col_name=\"mistral_7b\")\n",
        "ds_eval_7b = weave.Dataset(name=\"ds_eval_medium_7b\", description=\"Mistral 7b predictions\", rows=ds_eval_7b_rows)\n",
        "weave.publish(ds_eval_7b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "Let's use mistral large as a judge, let's compute a score as baseline comparing `7B` and `medium`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LLMJudge(weave.Model):\n",
        "    model: str = \"mistral-large-latest\"\n",
        "    \n",
        "    @weave.op\n",
        "    async def predict(self, question: str, mistral_7b: str, mistral_medium: str, answer: str) -> dict:\n",
        "        messages = [\n",
        "            ChatMessage(\n",
        "                role=\"user\",\n",
        "                content=(\n",
        "                \"You are an expert about Weights & Biases the ML platform. \"\n",
        "                \"You have to pick the best answer between two answers. \"\n",
        "                \"Take into consideration the context of the question and the ground truth answer as a reference. \\n\"\n",
        "                \"Here is the question: {question}\\n\"\n",
        "                \"Here is the answer1: {answer_7b}\\n\"\n",
        "                \"Here is the answer2: {answer_medium}\\n\"\n",
        "                \"Ground truth answer: {answer}\\n\"\n",
        "                \"Return the name of the best_answer and the reason in short JSON object.\").format(\n",
        "                    question=question, \n",
        "                    answer_7b=answer_7b, \n",
        "                    answer_medium=answer_medium,\n",
        "                    answer=answer)\n",
        "            )\n",
        "        ]\n",
        "        payload = await call_mistral(model=self.model, messages=messages, response_format={\"type\": \"json_object\"})\n",
        "        return json.loads(payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['question', 'answer', 'mistral-medium', 'mistral-7b'])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_eval_7b.rows[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "judge = LLMJudge()\n",
        "judge.predict(df.loc[0].question, res[\"answer\"], res[\"answer\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/6cf3932a-3c16-4e68-bff3-efc92a0d45e3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'best_answer': 'answer1',\n",
              " 'reason': 'Both answers are identical, but answer1 was provided first.'}"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_judge(df.loc[0].question, res[\"answer\"], res[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "@weave.op\n",
        "def evaluate_answer(question: str, model_output: str) -> dict:\n",
        "    \"Evaluate the answer\"\n",
        "    judgement = llm_judge(question, model_output, answer_medium, answer)\n",
        "    return {\"win\": judgement[\"best_answer\"] == \"answer1\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define a weave.evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the difference between team and organi...</td>\n",
              "      <td>A team is a collaborative workspace for a grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the difference between team and entity...</td>\n",
              "      <td>A team is a collaborative workspace for a grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is a team and where can I find more infor...</td>\n",
              "      <td>Use W&amp;B Teams as a central workspace for your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When should I log to my personal entity agains...</td>\n",
              "      <td>You should log to your personal entity when yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who can create a team? Who can add or delete p...</td>\n",
              "      <td>**Admin**: Team admins can add and remove othe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>How do I find an artifact from the best run in...</td>\n",
              "      <td>You can use the following code to retrieve the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>How do I save code in an artifact?‚Äå</td>\n",
              "      <td>Use `save_code=True` in `wandb.init` to save t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>Using artifacts with multiple architectures an...</td>\n",
              "      <td>There are many ways in which you can think of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>How can I fetch these Version IDs and ETags in...</td>\n",
              "      <td>If you've logged an artifact reference with W&amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>What is the artifact of type job I see in my a...</td>\n",
              "      <td>A launch job is a specific type of W&amp;B Artifac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>127 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  \\\n",
              "0    What is the difference between team and organi...   \n",
              "1    What is the difference between team and entity...   \n",
              "2    What is a team and where can I find more infor...   \n",
              "3    When should I log to my personal entity agains...   \n",
              "4    Who can create a team? Who can add or delete p...   \n",
              "..                                                 ...   \n",
              "122  How do I find an artifact from the best run in...   \n",
              "123                How do I save code in an artifact?‚Äå   \n",
              "124  Using artifacts with multiple architectures an...   \n",
              "125  How can I fetch these Version IDs and ETags in...   \n",
              "126  What is the artifact of type job I see in my a...   \n",
              "\n",
              "                                                answer  \n",
              "0    A team is a collaborative workspace for a grou...  \n",
              "1    A team is a collaborative workspace for a grou...  \n",
              "2    Use W&B Teams as a central workspace for your ...  \n",
              "3    You should log to your personal entity when yo...  \n",
              "4    **Admin**: Team admins can add and remove othe...  \n",
              "..                                                 ...  \n",
              "122  You can use the following code to retrieve the...  \n",
              "123  Use `save_code=True` in `wandb.init` to save t...  \n",
              "124  There are many ways in which you can think of ...  \n",
              "125  If you've logged an artifact reference with W&...  \n",
              "126  A launch job is a specific type of W&B Artifac...  \n",
              "\n",
              "[127 rows x 2 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = weave.Evaluation(dataset=df.iloc[0:10].to_dict(orient=\"records\"), scorers=[evaluate_answer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate_answer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'win'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.810741329193116</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'evaluate_answer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'win'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.810741329193116\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/749dca23-7481-42ea-9cb0-d1c893719b4e\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'evaluate_answer': {'win': {'true_count': 10, 'true_fraction': 1.0}},\n",
              " 'model_latency': {'mean': 5.810741329193116}}"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await evaluation.evaluate(mistral_7b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is pretty descent for both üòç. Let's see if fine-tuning improves this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_messages(row):\n",
        "    \"Format on the expected MistralAI fine-tuning dataset\"\n",
        "    question = row['question']\n",
        "    answer = row['answer']\n",
        "    messages = create_messages(question, cls=dict)\n",
        "    # we need to append the answer for training üëá\n",
        "    messages = {\"messages\":messages + [dict(role=\"assistant\", content=answer)]}\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': 'You are an expert about Weights & Biases the ML platform. You will answer questions about the product, Answer the question directly, without repeating the instructions.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"Sure, I'd be happy to help with your question about Weights & Biases. If you have a specific question about using Weights & Biases, such as how to track experiments, visualize data, or manage artifacts, please feel free to ask!\"},\n",
              "  {'role': 'user',\n",
              "   'content': 'Here is the question: What is the difference between team and organization?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'A team is a collaborative workspace for a group of users working on the same projects, while an organization is a higher-level entity that may consist of multiple teams and is often related to billing and account management.'}]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "msgs = format_messages(df.loc[0])\n",
        "msgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "MUBRITvX59kC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    {'messages': [{'role': 'user', 'content': 'You...\n",
              "1    {'messages': [{'role': 'user', 'content': 'You...\n",
              "2    {'messages': [{'role': 'user', 'content': 'You...\n",
              "3    {'messages': [{'role': 'user', 'content': 'You...\n",
              "4    {'messages': [{'role': 'user', 'content': 'You...\n",
              "dtype: object"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.apply(format_messages, axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_json(\"train.jsonl\", orient=\"records\", lines=True)\n",
        "df_eval.to_json(\"eval.jsonl\", orient=\"records\", lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu_oLukAJect"
      },
      "source": [
        "## Upload dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B0UlO1Qa7xi3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "\n",
        "api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
        "client = MistralClient(api_key=api_key)\n",
        "\n",
        "with open(\"train.jsonl\", \"rb\") as f:\n",
        "    ds_train = client.files.create(file=(\"train.jsonl\", f))\n",
        "with open(\"eval.jsonl\", \"rb\") as f:\n",
        "    ds_eval = client.files.create(file=(\"eval.jsonl\", f))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ChnYoKhoapES"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def pprint(obj):\n",
        "    print(json.dumps(obj.dict(), indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIAJdJIc9g2q",
        "outputId": "f5fc042e-8c06-473b-a616-536a0c6dd30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\",\n",
            "    \"object\": \"file\",\n",
            "    \"bytes\": 147176,\n",
            "    \"created_at\": 1719343148,\n",
            "    \"filename\": \"train.jsonl\",\n",
            "    \"purpose\": \"fine-tune\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "pprint(ds_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uA-Xnp1RTmx",
        "outputId": "ac0bdaba-4af1-4f19-a8ab-dd19482b1943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\",\n",
            "    \"object\": \"file\",\n",
            "    \"bytes\": 15339,\n",
            "    \"created_at\": 1719343148,\n",
            "    \"filename\": \"eval.jsonl\",\n",
            "    \"purpose\": \"fine-tune\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "pprint(ds_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqchXMeXJi6U"
      },
      "source": [
        "## Create a fine-tuning job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x9Qk42ADRVKo"
      },
      "outputs": [],
      "source": [
        "from mistralai.models.jobs import TrainingParameters, WandbIntegrationIn\n",
        "\n",
        "created_jobs = client.jobs.create(\n",
        "    model=\"open-mistral-7b\",\n",
        "    training_files=[ds_train.id],\n",
        "    validation_files=[ds_eval.id],\n",
        "    hyperparameters=TrainingParameters(\n",
        "        training_steps=25,\n",
        "        learning_rate=0.0001,\n",
        "        ),\n",
        "    integrations=[\n",
        "        WandbIntegrationIn(\n",
        "            project=\"mistral_webinar\",\n",
        "            run_name=\"finetune_wandb\",\n",
        "            api_key=os.environ.get(\"WANDB_API_KEY\"),\n",
        "        ).dict()\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkZlYvwGanL1",
        "outputId": "396cd040-643b-4296-b026-bb3589df44de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"QUEUED\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343209,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "pprint(created_jobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQXIE2G3c-Ds",
        "outputId": "83b955b3-5666-4b23-abbe-fa4dbe0ec676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": null,\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"RUNNING\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343210,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is RUNNING, waiting 10 seconds\n",
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:a063d186\",\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"SUCCESS\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343355,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"SUCCESS\"\n",
            "            },\n",
            "            \"created_at\": 1719343355\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n",
            "Job is SUCCESS, waiting 10 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "retrieved_job = client.jobs.retrieve(created_jobs.id)\n",
        "while retrieved_job.status in [\"RUNNING\", \"QUEUED\"]:\n",
        "    retrieved_job = client.jobs.retrieve(created_jobs.id)\n",
        "    pprint(retrieved_job)\n",
        "    print(f\"Job is {retrieved_job.status}, waiting 10 seconds\")\n",
        "    time.sleep(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x6wRaDtXDzt",
        "outputId": "1efa4948-0ca8-4bc1-85d2-7b72b7e4a931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"data\": [\n",
            "        {\n",
            "            \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 25,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:a063d186\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1719343209,\n",
            "            \"modified_at\": 1719343355,\n",
            "            \"training_files\": [\n",
            "                \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"mistral_webinar\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"finetune_wandb\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"5e4ed2f0-d940-42d6-903c-5773c8ed7caf\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 10,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:5e4ed2f0\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1719343155,\n",
            "            \"modified_at\": 1719343248,\n",
            "            \"training_files\": [\n",
            "                \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"mistral_webinar\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"finetune_wandb\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"64861646-2420-439a-97b0-739f35ca84bc\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 10,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:64861646\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1719342089,\n",
            "            \"modified_at\": 1719342173,\n",
            "            \"training_files\": [\n",
            "                \"78c99fec-4b0c-4a3f-b8f9-5473cf533753\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"57c1d237-8c88-4b0c-8b5a-c7c7be283761\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"mistral_webinar\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"finetune_wandb\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"8e246717-bae6-4a73-b119-3ff5d0900592\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 10,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:8e246717\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1719342077,\n",
            "            \"modified_at\": 1719342172,\n",
            "            \"training_files\": [\n",
            "                \"78c99fec-4b0c-4a3f-b8f9-5473cf533753\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"57c1d237-8c88-4b0c-8b5a-c7c7be283761\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"mistral_webinar\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"finetune_wandb\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"a404d92f-a840-438e-b7ae-a83bb1d642de\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 10,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:a404d92f\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1719332572,\n",
            "            \"modified_at\": 1719332657,\n",
            "            \"training_files\": [\n",
            "                \"78c99fec-4b0c-4a3f-b8f9-5473cf533753\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"57c1d237-8c88-4b0c-8b5a-c7c7be283761\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": []\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"dcd6f112-3d84-411e-a4c6-60417bee17a2\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 100,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240605:dcd6f112\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1717612154,\n",
            "            \"modified_at\": 1717613009,\n",
            "            \"training_files\": [\n",
            "                \"53021e72-f7d3-47e4-8f34-2ae4dd2b9ea3\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"13dc40ea-5692-44ff-9c5f-f3fb8378d08a\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"test_ft_api\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"test\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"310bfdc4-8e40-4092-80bf-aa0d7dd5b689\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 100,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": null,\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"FAILED\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1717607250,\n",
            "            \"modified_at\": 1717607276,\n",
            "            \"training_files\": [\n",
            "                \"53021e72-f7d3-47e4-8f34-2ae4dd2b9ea3\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"13dc40ea-5692-44ff-9c5f-f3fb8378d08a\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": [\n",
            "                {\n",
            "                    \"type\": \"wandb\",\n",
            "                    \"project\": \"test_ft_api\",\n",
            "                    \"name\": null,\n",
            "                    \"run_name\": \"test\"\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"186ddaa5-53f7-4aa3-8088-4b0124cc26af\",\n",
            "            \"hyperparameters\": {\n",
            "                \"training_steps\": 10,\n",
            "                \"learning_rate\": 0.0001\n",
            "            },\n",
            "            \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240605:186ddaa5\",\n",
            "            \"model\": \"open-mistral-7b\",\n",
            "            \"status\": \"SUCCESS\",\n",
            "            \"job_type\": \"FT\",\n",
            "            \"created_at\": 1717607116,\n",
            "            \"modified_at\": 1717607231,\n",
            "            \"training_files\": [\n",
            "                \"53021e72-f7d3-47e4-8f34-2ae4dd2b9ea3\"\n",
            "            ],\n",
            "            \"validation_files\": [\n",
            "                \"13dc40ea-5692-44ff-9c5f-f3fb8378d08a\"\n",
            "            ],\n",
            "            \"object\": \"job\",\n",
            "            \"integrations\": []\n",
            "        }\n",
            "    ],\n",
            "    \"object\": \"list\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# List jobs\n",
        "jobs = client.jobs.list()\n",
        "pprint(jobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhTWA5uJXHNp",
        "outputId": "a6db9934-a231-4650-d539-17c25e32b8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"a063d186-3eab-4b65-8fa3-bb081083e006\",\n",
            "    \"hyperparameters\": {\n",
            "        \"training_steps\": 25,\n",
            "        \"learning_rate\": 0.0001\n",
            "    },\n",
            "    \"fine_tuned_model\": \"ft:open-mistral-7b:0362203c:20240625:a063d186\",\n",
            "    \"model\": \"open-mistral-7b\",\n",
            "    \"status\": \"SUCCESS\",\n",
            "    \"job_type\": \"FT\",\n",
            "    \"created_at\": 1719343209,\n",
            "    \"modified_at\": 1719343355,\n",
            "    \"training_files\": [\n",
            "        \"d40cc185-6f0d-4754-bc05-5db7f6e3723a\"\n",
            "    ],\n",
            "    \"validation_files\": [\n",
            "        \"2a5b6582-3e90-4af6-800e-e9cf2d904bda\"\n",
            "    ],\n",
            "    \"object\": \"job\",\n",
            "    \"integrations\": [\n",
            "        {\n",
            "            \"type\": \"wandb\",\n",
            "            \"project\": \"mistral_webinar\",\n",
            "            \"name\": null,\n",
            "            \"run_name\": \"finetune_wandb\"\n",
            "        }\n",
            "    ],\n",
            "    \"events\": [\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"SUCCESS\"\n",
            "            },\n",
            "            \"created_at\": 1719343355\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"RUNNING\"\n",
            "            },\n",
            "            \"created_at\": 1719343210\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"status-updated\",\n",
            "            \"data\": {\n",
            "                \"status\": \"QUEUED\"\n",
            "            },\n",
            "            \"created_at\": 1719343209\n",
            "        }\n",
            "    ],\n",
            "    \"checkpoints\": [\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 0.855948,\n",
            "                \"valid_loss\": 1.668166,\n",
            "                \"valid_mean_token_accuracy\": 3.178103\n",
            "            },\n",
            "            \"step_number\": 20,\n",
            "            \"created_at\": 1719343301\n",
            "        },\n",
            "        {\n",
            "            \"metrics\": {\n",
            "                \"train_loss\": 1.148075,\n",
            "                \"valid_loss\": 1.647933,\n",
            "                \"valid_mean_token_accuracy\": 3.133843\n",
            "            },\n",
            "            \"step_number\": 10,\n",
            "            \"created_at\": 1719343271\n",
            "        }\n",
            "    ],\n",
            "    \"estimated_start_time\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Retrieve a jobs\n",
        "retrieved_jobs = client.jobs.retrieve(created_jobs.id)\n",
        "pprint(retrieved_jobs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK-cSS2EJv-e"
      },
      "source": [
        "## Use a fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': 'You are an expert about Weights & Biases the ML platform. You will answer questions about the product, Answer the question directly, without repeating the instructions.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"Sure, I'd be happy to help with your question about Weights & Biases. If you have a specific question about using Weights & Biases, such as how to track experiments, visualize data, or manage artifacts, please feel free to ask!\"},\n",
              "  {'role': 'user',\n",
              "   'content': 'Here is the question: What is the difference between `.log()` and `.summary`?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'The summary is the value that shows in the table while the log will save all the values for plotting later.\\n\\nFor example, you might want to call `wandb.log` every time the accuracy changes. Usually, you can just use .log. `wandb.log()` will also update the summary value by default unless you have set the summary manually for that metric\\n\\nThe scatterplot and parallel coordinate plots will also use the summary value while the line plot plots all of the values set by .log\\n\\nThe reason we have both is that some people like to set the summary manually because they want the summary to reflect for example the optimal accuracy instead of the last accuracy logged.\\n'}]}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_eval.iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üç© https://wandb.ai/capecape/mistral_webinar/r/call/eaccb136-f7d7-4191-a97f-2aaf8ebcf90a\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the difference between `.log()` and `.summary`?',\n",
              " 'answer': 'Use `.log()` to record scalar values that are not gradients, like loss or accuracy. Use `.summary()` to record scalars that are gradients (also called \"Vanilla scalars\" in the W&B App). The difference between logging scalars with `.log()` and `.summary()` is that `.summary()` automatically scales the scalars by the magnitude of the largest gradient seen so far for that scalar. This scaling makes it easier to compare different scalars with different units, such as loss (which is typically in the range [0, 1]) and learning rate (which is typically in the range [0, 1e-4]). For example, if you log both loss and learning rate with `.log()`, you\\'ll have to manually scale the learning rate to compare it to the loss. If you log both with `.summary()`, W&B will automatically scale the learning rate for you.'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb_expert(question=\"What is the difference between `.log()` and `.summary`?\", \n",
        "             model=retrieved_jobs.fine_tuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
